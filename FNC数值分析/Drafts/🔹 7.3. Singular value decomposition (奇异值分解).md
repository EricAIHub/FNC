## 🌟 问题背景：为什么要引入 SVD？

在矩阵分析中，**特征值分解（EVD）** 是一种重要工具，但它只适用于方阵，而且在数值上可能不稳定或不可用。

我们希望：

- 有一种 **适用于任意矩阵（方阵或长宽不等）** 的分解；
    
- 能获得与矩阵结构相关的固有成分；
    
- 方便计算矩阵的范数、秩、条件数；
    
- 提供低秩近似等应用能力。
    

这时出现了 **奇异值分解（Singular Value Decomposition）** —— 它是比 EVD 更普适、更稳定的矩阵分解。

---

## 🌟 SVD 的定义与公式

设 $A$ 是一个 $m\times n$ 复矩阵（实矩阵是其特例）。则 **奇异值分解（SVD）** 是把 $A$ 写成：

$$
A = U S V^*
$$

其中：

- $U\in\mathbb{C}^{m\times m}$ 是单位正交矩阵（实矩阵时为正交矩阵）；
    
- $V\in\mathbb{C}^{n\times n}$ 也是单位正交矩阵；
    
- $S\in\mathbb{R}^{m\times n}$ 是非负对角矩阵，其对角元素：
    

$$
\sigma_1 \ge \sigma_2 \ge \cdots \ge \sigma_r \ge 0,
\quad r = \min(m,n)
$$

这些 $\sigma_k$ 称为 **奇异值（singular values）**，分别对应的 $U$ 列为 **左奇异向量**，$V$ 列为 **右奇异向量**。

📌 奇异值按大小排序：$\sigma_1$ 称为主奇异值，对应的奇异向量常用于最主要模式分析。

---

## 🌟 存在性与唯一性

- **存在性**：每个矩阵（矩形或方阵）都至少有一个 SVD。
    
- **奇异值唯一性**：奇异值（$\sigma_k$）是唯一确定的，但对应的奇异向量并不是唯一的——可以乘以单位相位或符号不改变分解。
    
- 对于实矩阵，$U, V$ 可选成真实正交矩阵。
    

---

## 🌟 几何解释与直觉

SVD 可以从几何上理解为：

> 把 $A$ 作用在单位球面上的坐标变换分为三个步骤：
> 
> 1. 用 $V^*$ 把原坐标系旋转到一个正交基；
>     
> 2. 用对角缩放 $S$ 把各方向按不同尺度放大/缩小；
>     
> 3. 再用 $U$ 把结果旋转到目标空间。
>     

所以：

$$
A v_k = \sigma_k u_k
$$​

也就是说：

👉 每个右奇异向量 $v_k$ 被 $A$ 映射成对应的左奇异向量 $u_k$，并放大 $\sigma_k$ 倍。

---

## 🌟 SVD 与 EVD 的联系与差异

|特征值分解（EVD）|奇异值分解（SVD）|
|---|---|
|仅适用于方阵|适用于所有矩阵|
|一组基适用于域与像（domain & range）|使用两个正交基：域基 $V$ 和像基 $U$|
|可能条件很坏、甚至不能对角化|结构良好，存在性不依赖矩阵形状|

这个比较说明 SVD 在数学上更普适、数值上更稳定。

---

## 🌟 SVD 的“Thin”形式

对于 $A$ 是 $m\times n$（假设 $m > n$）：

标准 SVD 的 $S$ 有很多零行，这些是多余的。我们可以把 SVD 简化成：

$$
A = \hat{U} \hat{S} V^*
$$

其中：

- $\hat{U}$ 是 $m\times n$ 的正交矩阵
    
- $\hat{S}$ 是 $n\times n$ 对角阵
    

这种形式称为 **Thin SVD（细分解）**，比完整版节省存储空间，但不改变分解内容。

---

## 🌟 SVD 与矩阵 2-范数、秩、条件数

奇异值分解和矩阵的 2-范数、秩、条件数有密切关系：

1. **2-范数**（最大放大倍数）：
    

$$
\|A\|_2 = \sigma_1
$$


也就是说，矩阵作用下单位向量最大被放大的量就是最大奇异值。

2. **矩阵秩**：
    

$$
\operatorname{rank}(A) = \#\{\sigma_k > 0\}
$$

非零奇异值的数量就是矩阵的秩。

3. **伪逆与条件数**：
    

当所有奇异值都非零时，

$$
A^+ = V \hat{S}^{-1} \hat{U}^*
$$

是 Moore–Penrose 伪逆；条件数是：

$$
\kappa_2(A) = \frac{\sigma_1}{\sigma_r}
$$

其中 $\sigma_r$ 是最小非零奇异值。

---

## 🌟 核心定理：与 $\mathbf{A}^*\mathbf{A}$ 的关系

如果 $B = A^*A$，那么：

- $B$ 是对称（Hermitian）正半定的；
    
- 其非零特征值刚好是 $A$ 的奇异值的平方：$\lambda_k(B) = \sigma_k^2$
    
- 对应的特征向量是 $V$ 的列（右奇异向量）。
    
- 左奇异向量可以从 $A V = U S$ 得到。
    

这个关系让我们可以通过方阵的特征分解来构造 SVD。

---

## 🌟 为什么 SVD 这么重要？

SVD 的核心优势包括：

- **最优低秩近似**：Truncated SVD 给出最优的秩-$k$ 近似（在 Frobenius 和 2-范数意义下）；
    
- **数据分析基础**：在 PCA（主成分分析）中通过 SVD 提取主要方向；
    
- **数值稳定**：相比直接求逆或普通分解，SVD 对误差更不敏感；
    
- **适用于任意矩阵**：无论方阵、长宽不等矩阵，都可分解。
    

---

## 🌟 本节你必须记住的核心结论

| 核心点          | 要义                                   |
| ------------ | ------------------------------------ |
| **SVD 定义**   | $A = U S V^*$，$U, V$ 正交（或酉），$S$ 对角非负 |
| **奇异值**      | 非负、按大小排序的 $\sigma_k$                 |
| **存在性**      | 适用于任意矩阵                              |
| **Thin SVD** | 细分解形式更节省空间                           |
| **与特征分解的关系** | $A^*A$ 的非零特征值是 $\sigma_k^2$          |
| **范数与秩**     | $\|A\|_2=\sigma_1$，秩 = 非零奇异值数        |
| **条件数**      | $\kappa_2(A)=\sigma_1/\sigma_r$      |